\documentclass{article}
\author{Andrea Casalino}
\title{Gaussian Processes}

\usepackage{graphicx,color, import}
\usepackage{amssymb, amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage[toc,page]{appendix}

\begin{document}
\maketitle

\newpage
\section{What is a Gaussian Process?}

\textbf{Gaussian Processes} \cite{GP_general_01}, \cite{GP_general_02}, a.k.a. \textbf{GP}s, are
data driven probabiistic models able to approximate generic multivariate and possibly vectorial real functions $G$ defined like that:
\begin{eqnarray}
G : \mathcal{I} \subseteq \mathbb{R}^i \rightarrow \mathcal{O} \subseteq \mathbb{R}^o
\end{eqnarray}

In essence, \textbf{GP}s are defined by their own \textbf{Training Set} and \textbf{Kernel Function}.
The \textbf{Training Set} is a collection of points pertaining to $\mathcal{I}$, for which the corresponding output, or at least thst value summed with noise, inside $\mathcal{O}$ is known.
\\
The \textbf{Kernel Function} is something that has to be chosen and typical of the kind of function to approximate. Definitions and meanings of possible \textbf{Kernel Function} are extensively detailed in Section \ref{sec:kernel_function}.
\\
The aim of \textbf{GP}s is to be able to predict the value of $G$ for a point inside $\mathcal{I}$ that is not inside of the trainin set. In particular, this is done in probabilistic terms, as the result of the prediction is not just a value, but a conditioned Gaussian distribution.
\\
Section \ref{sec:scalar} discusses the formulation of scalar \textbf{GP}, i.e. cases for which $\mathcal{O} \subseteq \mathbb{R}$. Insted, Section \ref{sec:vectorial} focuses on the more general cases. The reader will notice that the two formulations are not in contradiction and the decision to discuss them into separate Sections is only for the purpose of a better readability. 

\section{Scalar case}
\label{sec:scalar}

The training set of a scalar \textbf{GP} is a collection of points inside $\mathcal{I}$ for which the corresponding value inside $\mathcal{O}$ is known. More formally:
\begin{eqnarray}
S &=& 
\bigg \lbrace 
\begin{bmatrix} X_1 \\ \downarrow \\ y_1 \end{bmatrix}, 
\hdots,  
\begin{bmatrix} X_N \\ \downarrow \\ y_N \end{bmatrix}
\bigg \rbrace \\
\big \lbrace X_1, \hdots, X_N \big \rbrace &\subset & \mathbb{R}^i \\
\big \lbrace y_1, \hdots, y_N \big \rbrace &\subset & \mathbb{R}
\end{eqnarray}

\textbf{GP}s consider values inside the training set to be somehow correlated, as they were generated from the same underlying function.
In particular, the joint probability distribution describing such correlation is assumed to be the following 0 mean \textbf{Gaussian Distribution}:
\begin{eqnarray}
\begin{bmatrix} y_1 \\ \vdots \\ y_N \end{bmatrix} \sim \mathcal{N} 
\bigg (
0, K \big( X_{1, \hdots, N} \big)
\bigg )  
\label{eq:y_joint_distr}
\end{eqnarray}

$K$ is a covariance matrix induced by the choice of a certain kernel function $k$ (refer also to Section \ref{sec:kernel_function}):
\begin{eqnarray}
K = \begin{bmatrix}
k(X_1, X_1, \Theta) & \hdots & k(X_1, X_N, \Theta) \\ 
\vdots & \ddots & \vdots \\ 
k(X_N, X_1, \Theta) & \hdots & k(X_N, X_N, \Theta) \\ 
\end{bmatrix}
\end{eqnarray}
where $\Theta$ is a vector of hyperparameters that are typical of the chosen kernel function and whose values can be tuned also by training (see Sections \ref{sec:train_scalar} and \ref{sec:train_vectorial}):
\begin{eqnarray}
\Theta = \begin{bmatrix} \theta_1 & \hdots & \theta_m \end{bmatrix} ^ T
\end{eqnarray}

It is generally a good practice to add to the covariance $K$ an additional term modelling noise in the traning set. This is done by simply summing an isotropic standard deviation $\sigma_{noise}$:
\begin{eqnarray}
K^{'} = K + \sigma_{noise} I_{N \times N} 
\end{eqnarray}

\subsection{Predictions}
\label{sec:predictions_scalar}

The aim of a \textbf{GP} is to be able to make predictions about the output value $y = G(X)$ pertaining o an input $X$ that is outside of the training set. This is done assuming again a joint Gaussian correlation between such an additional point and all the ones in the training set: 
\begin{eqnarray}
\begin{bmatrix} y = G(X) \\ \hline y_1 \\ \vdots \\ y_N \end{bmatrix} \sim \mathcal{N} 
\bigg (
\begin{bmatrix} 0 \\ \hline 0 \end{bmatrix},
\begin{bmatrix}
k(X,X, \Theta) & \vline & K_x(X, X_{1,\hdots,N}, \Theta) \\ 
\hline
K_x(X, X_{1,\hdots,N}, \Theta)^T & \vline & K
\end{bmatrix}
\bigg )
\end{eqnarray}
where $K_x$ is a vector assembled in this way:
\begin{eqnarray}
K_x(X, X_{1,\hdots,N}, \Theta) = \begin{bmatrix}
k(X, X_1 , \Theta) & \hdots & k(X, X_N , \Theta)
\end{bmatrix}^T
\label{eq:additional_joint}
\end{eqnarray}

Since eq. \ref{eq:additional_joint} describes a Gaussian distibution, the conditioned distribution involving only $X$ can be obtained as follows:
\begin{eqnarray}
y(X | X_{1,\hdots,N}) 
\sim \mathcal{N} \bigg ( 
K_x^T K^{-1} \begin{bmatrix} y_1 \\ \vdots \\ y_N \end{bmatrix} , 
\sigma_K(X)
\bigg )  
\label{eq:scalar_prediction}
\end{eqnarray}
where $\sigma_K(X)$ is the covariance of the conditioned distribution and can be computed as follows:
\begin{eqnarray}
\sigma_K(X) =
k(X,X) - K_x^T K^{-1} K_x
\end{eqnarray}

The distribution described by eq. \ref{eq:scalar_prediction}, actually represents the prediction made by the \textbf{GP}. Eq. \ref{eq:scalar_prediction} can also be rewritten as follows:
\begin{eqnarray}
y(X | X_{1,\hdots,N}) 
\sim \mathcal{N} \bigg (
\begin{bmatrix} y_1 & \hdots & y_N \end{bmatrix}
K^{-1} K_x, 
\sigma_K(X)
\bigg ) 
\end{eqnarray}

\subsection{Training}
\label{sec:train_scalar}

Training is done maximizing the likelihood $L$ of the training set w.r.t. the hyperparameters $\Theta$ of the kernel function.
Since eq. (\ref{eq:y_joint_distr}) describes a \textbf{Gaussian} distribution, the likelihood can be computed as follows:
\begin{eqnarray}
L = 
\frac{1}{\sqrt{(2 \pi)^N \left | K \right | }}
exp \bigg ( - \frac{1}{2}
\begin{bmatrix} y_1 & \hdots & y_N \end{bmatrix} 
K^{-1}
\begin{bmatrix} y_1 \\ \vdots \\ y_N \end{bmatrix} 
\bigg ) 
\end{eqnarray}
At this point, the property described in appendix \ref{sec:trace_property} can be exploited to rewrite the above equation as follows:
\begin{eqnarray}
L &=& 
\frac{1}{\sqrt{(2 \pi)^N \left | K \right | }}
exp \bigg ( - \frac{1}{2}
Tr \bigg [ 
K^{-1}
\begin{bmatrix} y_1 \\ \vdots \\ y_N \end{bmatrix} 
\begin{bmatrix} y_1 & \hdots & y_N \end{bmatrix} 
\bigg ]
\bigg ) \\
&=&
\frac{1}{\sqrt{(2 \pi)^N \left | K \right | }}
exp \bigg ( - \frac{1}{2}
Tr \bigg [ 
K^{-1}
M_{YY}
\bigg ]
\bigg )
\end{eqnarray}

Passing to the logarithm we obtain:
\begin{eqnarray}
\mathcal{L} = log(L) = 
-\frac{N}{2}(2 \pi) 
-\frac{1}{2} log \big (\left | K \right | \big )
-\frac{1}{2} Tr \bigg [
K^{-1} M_{YY}
\bigg ] 
\end{eqnarray}
keeping in mind that $\mathcal{L}$ is a function of the hyperparameters $\Theta$:
\begin{eqnarray}
\mathcal{L}(\Theta) = 
-\frac{N}{2}(2 \pi) 
-\frac{1}{2} log \big (\left | K(\Theta) \right | \big )
-\frac{1}{2} Tr \bigg [
K(\Theta)^{-1} M_{YY}
\bigg ] 
\end{eqnarray}

The gradient of $\mathcal{L}$ w.r.t. the generic hyperparameter $\theta_t$ is computed as follows (refer to the properties detailed at \cite{CookBook}):
\begin{eqnarray}
\frac{\partial \mathcal{L}}{\partial \theta_t} &=& 
-\frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} \bigg ]
-\frac{1}{2} Tr \bigg [ \frac{\partial }{\partial \theta_t} \big (  
K^{-1} M_{YY}
\big ) \bigg ] \\
&=& -\frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} \bigg ]
-\frac{1}{2} Tr \bigg [ \frac{\partial (K^{-1}) }{\partial \theta_t} M_{YY} \bigg ] \\
&=& -\frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} \bigg ]
+\frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} K^{-1} M_{YY} \bigg ] \\
&=&
\frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} \bigg (K^{-1} M_{YY} - I_{N \times N} \bigg ) \bigg ]
 \label{eq:L_grad}
\end{eqnarray}

Choosing your favourite gradient-based approach you can tune the model, byt computing the gradient as described by the above equation.

Check Section \ref{sec:prior} to understand how priors about the hyperparameters $\Theta$ can be handled.

\section{Vectorial case}
\label{sec:vectorial}

Vectorial \textbf{GP}s are defined as similarly done for the scalar case detailed in the previous Section.
The training set should now account for the multi-dimensionality of the process and is therefore defined in this way:
\begin{eqnarray}
S &=& 
\bigg \lbrace 
\begin{bmatrix} X_1 \\ \downarrow \\ Y_1 \end{bmatrix}, 
\hdots,  
\begin{bmatrix} X_N \\ \downarrow \\ Y_N \end{bmatrix}
\bigg \rbrace \\
\big \lbrace X_1, \hdots, X_N \big \rbrace &\subset & \mathbb{R}^i \\
\big \lbrace Y_1, \hdots, Y_N \big \rbrace &\subset & \mathbb{R}^o
\end{eqnarray}
The generic $Y_k$ is a vector made of $o$ components:
\begin{eqnarray}
Y_k = \begin{bmatrix} y_k^1 & \hdots & y_k^o \end{bmatrix}^T
\end{eqnarray}

\subsection{Predictions}

A vectorial \textbf{GP} is actually a composition of independent scalar \textbf{GP}s.
The prediction is done as similarly discussed in Section \ref{sec:predictions_scalar}, doing $o$ predictions at the same time. Indeed, for each component $y^{k \in \lbrace 1, \hdots ,o\rbrace}$ of the prediction  holds equation \ref{eq:scalar_prediction}. Therefore, the complete prediction can be obtained in this way:
\begin{eqnarray}
Y(X| X_{1,\hdots,N}) = \begin{bmatrix}
\mathcal{N} \bigg (
\begin{bmatrix} y^1_1 & \hdots & y^1_N \end{bmatrix}
K^{-1} K_x, 
\sigma_K(X)
\bigg ) \\ 
\vdots \\
\mathcal{N} \bigg (
\begin{bmatrix} y^o_1 & \hdots & y^o_N \end{bmatrix}
K^{-1} K_x, 
\sigma_K(X)
\bigg ) 
\end{bmatrix} 
\end{eqnarray}
the above expression can be further elaborated, leading to the distribution of an isotropic Gaussian:
\begin{eqnarray}
Y(X| X_{1,\hdots,N}) 
&\sim &
\mathcal{N} \bigg (
\begin{bmatrix} 
y^1_1 & \hdots & y^1_N \\
\vdots & \ddots & \vdots \\
y^o_1 & \hdots & y^o_N
\end{bmatrix} K^{-1} K_x
, \sigma_K(X) I_{o \times o}
\bigg )
\\
&\sim &
\mathcal{N} \bigg (
\begin{bmatrix} Y_1 | & \hdots & | Y_N \end{bmatrix} K^{-1} K_x
, \sigma_K(X) I_{o \times o}
\bigg )
\end{eqnarray}

\subsection{Training}
\label{sec:train_vectorial}

The logarithmic likelihood is the summation of the logarithmic likelihood of each process that compose the vectorial \textbf{GP}, which leads, omitting constant terms, to:
\begin{eqnarray}
\mathcal{L} &=& 
\sum_{k=1}^o \bigg (
-\frac{1}{2} log \big (\left | K \right | \big )
-\frac{1}{2} Tr \bigg [
K^{-1} 
\begin{bmatrix} y^i_1 \\ \vdots \\ y^i_N \end{bmatrix}
\begin{bmatrix} y^i_1 & \hdots & y^i_N \end{bmatrix}
\bigg ] \bigg )  \\
&=&
-\frac{o}{2} log \big (\left | K \right | \big )
-\frac{1}{2} \sum_{k=1}^o \bigg ( Tr \bigg [
K^{-1} 
\begin{bmatrix} y^i_1 \\ \vdots \\ y^i_N \end{bmatrix}
\begin{bmatrix} y^i_1 & \hdots & y^i_N \end{bmatrix}
\bigg ] 
\bigg ) \\
&=&
-\frac{o}{2} log \big (\left | K \right | \big )
-\frac{1}{2} Tr \bigg [
K^{-1} \sum_{k=1}^o \bigg (
\begin{bmatrix} y^i_1 \\ \vdots \\ y^i_N \end{bmatrix}
\begin{bmatrix} y^i_1 & \hdots & y^i_N \end{bmatrix}
\bigg )
\bigg ] \\
&=&
-\frac{o}{2} log \big (\left | K \right | \big )
-\frac{1}{2} Tr \bigg [
K^{-1} M^o_{YY}
\bigg ] 
\end{eqnarray}
with:
\begin{eqnarray}
M^o_{YY} 
&=& \sum_{k=1}^o \bigg (
\begin{bmatrix} y^i_1 \\ \vdots \\ y^i_N \end{bmatrix}
\begin{bmatrix} y^i_1 & \hdots & y^i_N \end{bmatrix}
\bigg ) \\
&=& \sum_{k=1}^o 
\begin{bmatrix}
y^i_1 y^i_1 & \hdots & y^i_1 y^i_N \\ 
\vdots & \ddots & \vdots \\ 
y^i_N y^i_1 & \hdots & y^i_N y^i_N
\end{bmatrix} \\
&=& \begin{bmatrix}
\sum_{k=1}^o y^i_1 y^i_1 & \hdots & \sum_{k=1}^o y^i_1 y^i_N \\ 
\vdots & \ddots & \vdots \\ 
\sum_{k=1}^o y^i_N y^i_1 & \hdots & \sum_{k=1}^o y^i_N y^i_N
\end{bmatrix} \\
&=& \begin{bmatrix}
<Y_1, Y_1> & \hdots  & <Y_1, Y_N> \\ 
\vdots & \ddots & \vdots \\ 
<Y_N, Y_1> & \hdots & <Y_N, Y_N>
\end{bmatrix}
\end{eqnarray}
keeping again in mind that $\mathcal{L}$ is a function of the hyperparameters $\Theta$:
\begin{eqnarray}
\mathcal{L}(\Theta) = -\frac{o}{2} log \big (\left | K \big (\Theta \big ) \right | \big )
-\frac{1}{2} Tr \bigg [
K^{-1}\big (\Theta \big ) M^o_{YY}
\bigg ] 
\end{eqnarray}
The gradient can be computed with the same steps that led to 
eq. (\ref{eq:L_grad}), leading to:
\begin{eqnarray}
\frac{\partial \mathcal{L}}{\partial \theta_t} = \frac{1}{2} Tr \bigg [ K^{-1} \frac{\partial K}{\partial \theta_t} \bigg (K^{-1} M^o_{YY} - o I_{N \times N} \bigg ) \bigg ]
\end{eqnarray}

\subsubsection{Hyperparameters prior knowledge}
\label{sec:prior}

It is possible to also take into account an a-priori knowledge of the process, in terms of a prior distribution describing the hyperparameters values. Such priors modify the likelihood function to optimize in this way:
\begin{eqnarray}
L^{'}(\Theta) = L(\Theta) L(\Theta)_{prior} 
\label{eq:prior_likelihood}
\end{eqnarray}

In principle, any distribution can be used as a prior for the hyperparameters. Without loss of generality, assume the prior is modelled with a multivariate gaussian distribution defined by a certain mean $\mu_{prior}$ and covariance $\Sigma_{prior}$. 
In such a case, equation (\ref{eq:prior_likelihood}) became:
\begin{eqnarray}
L^{'}(\Theta) \propto L(\Theta) 
exp \bigg ( -\frac{1}{2} \big(\Theta - \mu_{prior}\big)^T \Sigma^{-1}_{prior} \big(\Theta - \mu_{prior}\big) \bigg )
\end{eqnarray}

passing to the logarithm and neglecting constant values we get:
\begin{eqnarray}
\mathcal{L}^{'}(\Theta) = \mathcal{L}(\Theta)
-\frac{1}{2} \big(\Theta - \mu_{prior}\big)^T \Sigma^{-1}_{prior} \big(\Theta - \mu_{prior}\big) 
\end{eqnarray}

Clearly, the gradient of the complete likelihood $\mathcal{L}^{'}(\Theta)$ can be computed as follows:
\begin{eqnarray}
\frac{\partial \mathcal{L}^{'}}{\partial \Theta}^T = 
\frac{\partial \mathcal{L}}{\partial \Theta}^T - \Sigma^{-1}_{prior} \big( \Theta - \mu_{prior} \big)
\end{eqnarray}

\section{Kernel functions}
\label{sec:kernel_function}

The kernel function describes the correlation between the inputs. Ideally, it should assume a low value for inputs that are "far", w.r.t. a certain metrics, from each other and high values for those inputs that are close.
\\
The kernel function $k$ should be designed in order to produce a symemtric positive definite matrix $K$, as this latter should be representative of a covariance matrix, see eq. (\ref{eq:y_joint_distr}).
\\
Clearly, the gradient of $K$ can be computed element by element:
\begin{eqnarray}
\frac{\partial K}{\partial \theta_t} = 
\begin{bmatrix}
\frac{\partial k(X_1, X_1)}{\partial \theta_t} & \hdots & \frac{\partial k(X_1, X_N)}{\partial \theta_t} \\ 
\vdots & \ddots & \vdots \\ 
\frac{\partial k(X_N, X_1)}{\partial \theta_t} & \hdots & \frac{\partial k(X_N, X_N)}{\partial \theta_t} \\ 
\end{bmatrix}
\end{eqnarray}
\\
In the following of this Section, some of the most popular kernel functions \footnote{Which are also the ones default supported by this package.}  will be discussed.

\subsection{Linear function}

Hyperparameters:
\begin{eqnarray}
\Theta = \begin{bmatrix} \theta_0 & \theta_1 & \mu_1 & \hdots & \mu_o \end{bmatrix}
\end{eqnarray}

Fuction evaluation:
\begin{eqnarray}
k(a,b,\Theta) 
&=&
\theta_0^2 + \theta_1^2 \big ( a-\mu \big )^T \big ( b-\mu \big ) \\
&=&
\theta_0^2 + \theta_1^2 \big ( <\mu, \mu> + <a, b> - <\mu, a + b> \big )
\end{eqnarray}

Function gradient:
\begin{eqnarray}
\frac{\partial k (a,b)}{\partial \theta_0} &=& 2 \theta_0 \\
\frac{\partial k (a,b)}{\partial \theta_1} &=& 2 \theta_1 \big ( a - \mu \big ) \big ( b - \mu \big ) \\
\begin{bmatrix} 
\frac{\partial k (a,b)}{\partial \mu_1} 
\\ 
\vdots
\\ 
\frac{\partial k (a,b)}{\partial \mu_o} 
\end{bmatrix}
&=& \theta_1^2 \big ( 2\mu - a - b \big )
\end{eqnarray}

\subsection{Squared exponential}

Hyperparameters:
\begin{eqnarray}
\Theta = \begin{bmatrix} \sigma & d \end{bmatrix}
\end{eqnarray}

Fuction evaluation:
\begin{eqnarray}
k(a,b,\Theta) =
\sigma^2 exp \bigg ( - \frac{\left \| a - b \right \| ^2_2}{d^2}  \bigg ) 
\end{eqnarray}

Function gradient:
\begin{eqnarray}
\frac{\partial k (a,b)}{\partial \sigma} &=& 2 \sigma exp \bigg ( - \frac{\left \| a - b \right \| ^2_2}{d^2}  \bigg ) \\
\frac{\partial k (a,b)}{\partial d} &=& \sigma^2 exp \bigg ( - \frac{\left \| a - b \right \| ^2_2}{d^2}  \bigg )
2 \frac{\left \| a - b \right \| ^2_2}{d^3}
\end{eqnarray}

\subsection{Periodic kernel}

This function is able to well express the periodicity in the function to approximate. The yyperparameters are:
\begin{eqnarray}
\Theta = \begin{bmatrix} \sigma & d & p \end{bmatrix}
\end{eqnarray}
$p$ represents the period of the kernel function.

Fuction evaluation:
\begin{eqnarray}
k(a,b,\Theta) =
\sigma^2 exp \bigg ( -\frac{sin^2 \big( \frac{2 \pi}{p} \left \| a - b \right \| _2 \big)}{d^2}  \bigg )
= \sigma^2 exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg )
\end{eqnarray}

Function gradient:
\begin{eqnarray}
\frac{\partial k (a,b)}{\partial \sigma} &=& 2 \sigma exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg ) \\
\frac{\partial k (a,b)}{\partial d} &=& \sigma^2 exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg ) 2 \frac{sin^2 \big( \alpha \big)}{d^3} \\
\frac{\partial k (a,b)}{\partial p} 
&=&  \sigma^2 exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg ) \bigg ( - \frac{2 sin \big( \alpha \big) cos \big( \alpha \big)}{ d^2} \bigg ) \frac{\partial \alpha}{ \partial p} \nonumber \\
&=& \sigma^2 exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg ) \bigg ( - \frac{2 sin \big( \alpha \big) cos \big( \alpha \big)}{ d^2} \bigg ) \bigg ( - \frac{2 \pi \left \| a - b \right \| _2}{p^2} \bigg ) \nonumber \\
&=& \sigma^2 exp \bigg ( -\frac{sin^2 \big( \alpha \big)}{d^2}  \bigg ) \frac{2 sin \big( \alpha \big) cos \big( \alpha \big) \alpha}{p d^2}  
\end{eqnarray}

% \subsection{What to expect from the predictions}
% TODO spiegare che incertezza aumenta tanto piu sonon lontano da punti in training set

\subsection{Combining kernel functions}

Clearly, you can also combine the kernel functions described in this Section to create more complex one.

\subsubsection{Summation}

You can sum more kernel functions $k_{1,\hdots,m}$ together, each having its own group of hyperparameters $\Theta_{1,\hdots,m}$:
\begin{eqnarray}
\Theta &=& \begin{bmatrix} \Theta_1^T & \hdots & \Theta_m^T \end{bmatrix}^T \\
k(a,b,\Theta) &=& \sum_{i=1}^m k_i(a,b,\Theta_i)
\end{eqnarray}

The gradient is clearly computed as follows:
\begin{eqnarray}
\frac{\partial k(a,b)}{\partial \Theta}^T = \begin{bmatrix}
\frac{\partial k_1(a,b)}{\partial \Theta_1}^T
\\ 
\vdots
\\ 
\frac{\partial k_m(a,b)}{\partial \Theta_m}^T
\end{bmatrix}
\end{eqnarray}

\subsubsection{Product}

You can multiply bunch of kernel functions $k_{1,\hdots,m}$ together, each having its own group of hyperparameters $\Theta_{1,\hdots,m}$:
\begin{eqnarray}
\Theta &=& \begin{bmatrix} \Theta_1^T & \hdots & \Theta_m^T \end{bmatrix}^T \\
k(a,b,\Theta) &=& \prod_{i=1}^m k_i(a,b,\Theta_i)
\end{eqnarray}

The gradient is clearly computed as follows:
\begin{eqnarray}
\frac{\partial k(a,b)}{\partial \Theta}^T = 
\bigg( \prod_{i=1}^m k_i(a,b) \bigg)
\begin{bmatrix}
\frac{\partial k_1(a,b)}{\partial \Theta_1}^T \frac{1}{k_1(a,b)}
\\ 
\vdots
\\ 
\frac{\partial k_m(a,b)}{\partial \Theta_m}^T \frac{1}{k_m(a,b)}
\end{bmatrix}
\end{eqnarray}

\appendix

\section{Trace property}
\label{sec:trace_property}

Take an $(n,n)$ matrix $A$ and a vector $X$, the scalar quantity $x^T A x$ is equal to:
\begin{eqnarray}
x^T A x &=& Tr \bigg [ 
A xx^T
\bigg ]
\label{eq:Tr_property}
\\
&=& Tr \bigg [ 
xx^T A^T
\bigg ]
\end{eqnarray}
Clearly, in case of symmetric matrix, the following holds:
\begin{eqnarray}
x^T A x = Tr \bigg [ 
xx^T A
\bigg ]
\end{eqnarray}

We will now prove equation (\ref{eq:Tr_property}).
\\
$x^T A x$ can be also expressed as follows:
\begin{eqnarray}
x^T A x &=& x^T \begin{bmatrix} 
a_1^T \\
\vdots \\ 
a_n^T
\end{bmatrix} x \\
&=&
x^T \begin{bmatrix} 
a_1^T x \\
\vdots \\ 
a_n^T x
\end{bmatrix} = x^T \begin{bmatrix} 
<a_1, x> \\
\vdots \\ 
<a_n, x>
\end{bmatrix} \\
&=&
\sum_{i = 1}^n x_i <a_i, x>
\label{eq:sum_dots_a}
\end{eqnarray}
where $a_i$ is the $i^{th}$ row of $A$.
At the same time, the following fact is also true:
\begin{eqnarray}
Tr \bigg [ A x x^T \bigg ] &=& 
Tr \bigg [
\begin{bmatrix} a_1^T \\ \vdots \\ a_n^T \end{bmatrix}
\begin{bmatrix} xx_1 & \hdots & xx_n \end{bmatrix}
\bigg ]  \\
&=&
Tr \bigg [
\begin{bmatrix} 
a_1^T xx_1 & & \\
& \ddots & \\
& & a_n^T xx_n
\end{bmatrix}
\bigg ] \\
&=&
\sum_{i = 1}^n x_i <a_i, x>
\label{eq:sum_dots_b}
\end{eqnarray}
where we recognize that eq. (\ref{eq:sum_dots_a}) and (\ref{eq:sum_dots_b}) are identical.

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
